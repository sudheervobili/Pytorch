{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bh8MJX8prXxl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#inputs\n",
        "x = torch.tensor(6.7)\n",
        "y = torch.tensor(0.0) #target\n",
        "\n",
        "w = torch.tensor(1.0) #weight\n",
        "b = torch.tensor(0.0) #bias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy_loss(prediction,target): # function for calculating loss\n",
        "  epslion = 1e-8\n",
        "  prediction = torch.clamp(prediction,epslion,1-epslion)\n",
        "  return -target*torch.log(prediction)-(1-target)*torch.log(1-prediction)"
      ],
      "metadata": {
        "id": "ImpRGEVOshWK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = w*x+b #linear transformation\n",
        "y_pred = torch.sigmoid(z) #sigmoid func\n",
        "loss = binary_cross_entropy_loss(y_pred,y) #loss func\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1S8tW3TtpDB",
        "outputId": "5783c25d-f66b-4838-9245-0193fbf12410"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.7012)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#derivatives for dL/dw and dL/db\n",
        "dloss_dy_pred = (y_pred-y)/(y_pred*(1-y_pred))\n",
        "dy_pred_dz = y_pred*(1-y_pred)\n",
        "dz_dw = x\n",
        "dz_db = 1\n",
        "dloss_dw = dloss_dy_pred*dy_pred_dz*dz_dw\n",
        "dloss_db = dloss_dy_pred*dy_pred_dz*dz_db\n",
        "\n",
        "print(f\"Gradient w.r.t w: {dloss_dw.item():.4f}\")\n",
        "print(f\"Gradient w.r.t b: {dloss_db.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIrjYYBUt7Ct",
        "outputId": "7f633847-a315-4af9-d8b8-73de1b83fc1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t w: 6.6918\n",
            "Gradient w.r.t b: 0.9988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Auto-grad method**"
      ],
      "metadata": {
        "id": "9E6pjgH6xSmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(6.7,requires_grad=True)\n",
        "Y = torch.tensor(0.0) #target"
      ],
      "metadata": {
        "id": "uKThZbFwuSPi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.tensor(1.0,requires_grad=True) #weight\n",
        "b1 = torch.tensor(0.0,requires_grad=True) #bias"
      ],
      "metadata": {
        "id": "L5YeayyNxhpw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1,b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvJZZG36xm_L",
        "outputId": "03c81802-ebf3-4902-eb5d-da0febab8a77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1., requires_grad=True), tensor(0., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = w1*X+b1 #linear transformation\n",
        "y_pred1 = torch.sigmoid(z1) #sigmoid func\n",
        "loss1 = binary_cross_entropy_loss(y_pred1,Y) #loss func\n",
        "print(loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAxN9rYSxvUC",
        "outputId": "086ec672-cb35-49b7-c82a-95c6ae2f10c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.7012, grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss1.backward()"
      ],
      "metadata": {
        "id": "q0WYZFvPyNXy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w1.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe_AlW4HyUfg",
        "outputId": "58df06d0-4f58-4c8e-be2f-02c2a8f096ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6918)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rMrnmNUyVgn",
        "outputId": "6fe13d03-4246-428b-cdb7-7bb7f09c449e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9988)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ----- Step 1: Define input tensors -----\n",
        "a = torch.tensor(4.0, requires_grad=True)\n",
        "p = torch.tensor(2.0, requires_grad=True)\n",
        "q = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# ----- Step 2: Forward computation -----\n",
        "intermediate = a * p + q    # like linear layer: z = ap + q\n",
        "intermediate.retain_grad()  # allows us to access its gradient\n",
        "\n",
        "z = intermediate ** 2       # final output\n",
        "\n",
        "# ----- Step 3: Backward (compute gradients) -----\n",
        "z.backward()  # triggers autograd\n",
        "\n",
        "# ----- Step 4: Print gradients -----\n",
        "print(f\"∂z/∂a: {a.grad.item():.2f}\")\n",
        "print(f\"∂z/∂p: {p.grad.item():.2f}\")\n",
        "print(f\"∂z/∂q: {q.grad.item():.2f}\")\n",
        "print(f\"∂z/∂intermediate: {intermediate.grad.item():.2f}\")  # thanks to retain_grad()\n",
        "\n",
        "# ----- Step 5: Clear gradients for next pass -----\n",
        "a.grad.zero_()\n",
        "p.grad.zero_()\n",
        "q.grad.zero_()\n",
        "\n",
        "# ----- Step 6: Detach intermediate for logging (no gradient tracking) -----\n",
        "detached_intermediate = intermediate.detach()\n",
        "print(f\"Detached intermediate: {detached_intermediate.item():.2f}\")\n",
        "\n",
        "# ----- Step 7: Do inference without tracking gradients -----\n",
        "with torch.no_grad():\n",
        "    new_output = (a * p + q) ** 2\n",
        "    print(f\"New output without gradient tracking: {new_output.item():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNDuZeUsyht0",
        "outputId": "c339cb0c-9e64-4901-9ad5-214e958dae2f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "∂z/∂a: 36.00\n",
            "∂z/∂p: 72.00\n",
            "∂z/∂q: 18.00\n",
            "∂z/∂intermediate: 18.00\n",
            "Detached intermediate: 9.00\n",
            "New output without gradient tracking: 81.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPgwDjTk010O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}